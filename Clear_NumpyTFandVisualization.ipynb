{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lee-53/ECE-4380-F25/blob/main/Clear_NumpyTFandVisualization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Numpy, TF, and Visualization"
      ],
      "metadata": {
        "id": "gpxEYIAp_U8v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Start by importing necessary packages\n",
        "We will begin by importing necessary libraries for this notebook. Run the cell below to do so."
      ],
      "metadata": {
        "id": "9TaaBpdD_kSm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubthxJmH_TQB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizations\n",
        "\n",
        "Visualization is a key factor in understanding deep learning models and their behavior. Typically, pyplot from the matplotlib package is used, capable of visualizing series and 2D data.\n",
        "\n",
        "Below is an example of visualizing series data."
      ],
      "metadata": {
        "id": "k_k7WF41ATPs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.linspace(-5, 5, 50) # create a linear spacing from x = -5.0 to 5.0 with 50 steps\n",
        "\n",
        "y1 = x**2      # create a series of points {y1}, which corresponds to the function f(x) = y^2\n",
        "y2 = 4*np.sin(x) # create another series of points {y2}, which corresponds to the function f(x) = 4*sin(x)  NOTE: we have to use np.sin and not math.sin as math.sin will only act on individual values\n",
        "# to use math.sin, we could have used a list comprehension instead: y2 = [math.sin(xi) for xi in x]\n",
        "\n",
        "# by default, matplotlib will behave like MATLAB with hold(True), overplotting until a new figure object is created\n",
        "plt.plot(x, y1, label=\"x^2\")        # plot y1 with x as the x-axis series, and label the line \"x^2\"\n",
        "plt.plot(x, y2, label=\"4 sin(x)\")   # plot y2 with x as the x-axis series, and label the line \"4 sin(x)\"\n",
        "plt.legend()                        # have matplotlib show the label on the plot"
      ],
      "metadata": {
        "id": "RtNBq8ej_sEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "More complex formatting can be added to increase the visual appeal and readability of plots (especially for paper quality figures).\n",
        "To try this out, let's consider plotting a few of the more common activation functions used in machine learning.\n",
        "Below, plot the following activation functions for $x\\in[-4, 4]$:\n",
        "\n",
        "\n",
        "*   ReLU: $max(x, 0)$\n",
        "*   Leaky-ReLU: $max(0.1\\cdot x, x)$\n",
        "*   Sigmoid: $\\sigma(x) = 1/(1 + e^{-x})$\n",
        "*   Hyperbolic Tangent: $\\mathrm{tanh}(x) = (e^{x} - e^{-x})/(e^{x} + e^{-x})$\n",
        "*   SiLU: $x \\cdot \\sigma(x)$\n",
        "*   GeLU: $x \\cdot \\frac{1}{2} \\left(1 + \\mathrm{erf}\\left(\\frac{x}{\\sqrt{2}}\\right)\\right)$\n",
        "*   tanh GELU: $x \\cdot \\frac{1}{2} \\left(1 + \\mathrm{tanh}\\left(\\frac{x}{\\sqrt{2}}\\right)\\right)$\n",
        "\n",
        "Plot the GELU and tanh GELU using the same color, but with tanh using a dashed line (tanh is a common approximation as the error-function is computationally expensive to compute).\n",
        "You may also need to adjust the legend to make it easier to read.\n",
        "I recommend using ChatGPT to help find the formatting options here.\n",
        "\n",
        "**Question 1**\n",
        "\n"
      ],
      "metadata": {
        "id": "UH7U56pHCw_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.linspace(-4, 4, 50) # create a linear spacing from x = -4.0 to 4.0 with 50 steps\n",
        "# create and plot the functions below"
      ],
      "metadata": {
        "id": "hjdDo8kTBZe-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer to the following questions from the the plot you just created:\n",
        "\n",
        "\n",
        "1.   Which activation function is the least computationally expensive to compute?\n",
        "2.   Are there better choices to ensure more stable training? What downfalls do you think it may have?\n",
        "3.   Are there any cases where you would not want to use either activation function?\n",
        "\n",
        "**Question 2**"
      ],
      "metadata": {
        "id": "YUk3xiwVI3sM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iuwMclyzKDcf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing 2D data\n",
        "\n",
        "In many cases, we also want the ability to visualize multi-dimensional data such as images. To do so, matplotlib has the imshow method, which can visualize single channel data with a heatmap, or RGB data with color.\n",
        "\n",
        "Let's consider visualizing the first 8 training images from the MNIST dataset. MNIST consists of hand drawn digits with their corresponding labels (a number from 0 to 9).\n",
        "\n",
        "We will use the tensorflow keras dataset library to load the dataset, and then visualize the images with a matplotlib subplot.\n",
        "Because we have so many images, we should arrange them in a grid (4 horizontal, 2 vertical), and plot each image in a loop.\n",
        "Furthermore, we can append the label to each image using the matplotlib utility.\n"
      ],
      "metadata": {
        "id": "rLvPfSZdKI_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Define the grid dimensions\n",
        "rows, cols = 2, 4\n",
        "\n",
        "# Create a figure and axes for the grid\n",
        "fig, axes = plt.subplots(rows, cols, figsize=(8, 5))\n",
        "\n",
        "# Iterate through the grid\n",
        "for i in range(rows):\n",
        "    for j in range(cols):\n",
        "        index = i * cols + j\n",
        "        ax = axes[i, j]\n",
        "\n",
        "        # Display the image\n",
        "        ax.imshow(train_images[index], cmap='gray')\n",
        "\n",
        "        # Display the label on top of the image in red text\n",
        "        ax.text(0.9, 0.9, str(train_labels[index]), color='red',\n",
        "                transform=ax.transAxes, fontsize=24,\n",
        "                ha='center', va='center')\n",
        "\n",
        "        # Turn off axis labels\n",
        "        ax.axis('off')\n",
        "\n",
        "# Adjust spacing and layout\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "KMTxcyO6Fcvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another popular image dataset for benchmarking and evaluation is CFAR-10. This dataset consists of small (32 x 32 pixel) RGB images of objects that fall into one of 10 classes:\n",
        "\n",
        "0.   airplane\n",
        "1.   automobile\n",
        "2.   bird\n",
        "3.   cat\n",
        "4.   deer\n",
        "5.   dog\n",
        "6.   frog\n",
        "7.   horse\n",
        "8.   ship\n",
        "9.  truck\n",
        "\n",
        "\n",
        "Plot the first 32 images in the dataset using the same method above.\n",
        "\n",
        "**Question 3**"
      ],
      "metadata": {
        "id": "3eBymk5gMMja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "\n",
        "# add your plotting code below"
      ],
      "metadata": {
        "id": "c_VYF-eAKs5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing Tensors\n",
        "\n",
        "Aside from visualzing linear functions and images, we can also visualize entire tensors from DL models."
      ],
      "metadata": {
        "id": "yHqAWvIoODLu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# first, let's download an existing model to inspect\n",
        "model = tf.keras.applications.VGG16(weights='imagenet')\n",
        "\n",
        "# can then print the summary of what the model is composed of\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "zgIul9k-MuhB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we can also print the model layers based on index to better understand the structure\n",
        "for i,layer in enumerate(model.layers):\n",
        "  print(f\"{i}: {layer}\")"
      ],
      "metadata": {
        "id": "lo8-lE0nToi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not all of these layers contain weights, for example, MaxPooling2D is a stateless operation, and so is Flatten.\n",
        "Conv2D and Dense are the two layer types that can be visualized.\n",
        "That said, let's visualize the filter kernels in the first convoluton layer."
      ],
      "metadata": {
        "id": "g5p0AaiERxm8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# next we can extract som\n",
        "layer = model.layers[1] # Get the first convolutional layer\n",
        "weights = layer.get_weights()[0]\n",
        "\n",
        "n_filters = weights.shape[-1]\n",
        "\n",
        "for i in range(n_filters):\n",
        "    plt.subplot(8, 8, i+1)  # Assuming 64 filters, adjust if necessary\n",
        "    plt.imshow(weights[:, :, 0, i], cmap=\"viridis\")\n",
        "    plt.axis('off')"
      ],
      "metadata": {
        "id": "ZT8RUY0zP9cv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aside from visualizing the weights directly, we can also compute and visualize the weight distribution using a histogram."
      ],
      "metadata": {
        "id": "lTXSJJA0Sbx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# we can use the mean and var (variance) functions built in to calculate some simple statistics\n",
        "print(f\"weight tensor has mean: {weights.mean()} and variance: {weights.var()}\")\n",
        "\n",
        "# we need to call .flatten() on the tensor so that all the histogram sees them as a 1D array. Then we can plot with 100 bins to get a bit more resolution in the histogram.\n",
        "plt.hist(weights.flatten(), bins=100)"
      ],
      "metadata": {
        "id": "bUmk-GHmQN72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Look through the other weight tensors in the network and note any patterns that can be observed. Plot some examples in a subplot grid (include at least 4 plots).\n",
        "You can also overplot on the same subplot if you find that helpful for visualization.\n",
        "\n",
        "**Question 4**"
      ],
      "metadata": {
        "id": "WvjqrFp6Up7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# enter plot code below"
      ],
      "metadata": {
        "id": "mQRiA7cMTTGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also visualize the activations within the network, this is done by applying a forward pass with a data input, and extracting the intermediate result. Below is an example output from the first convolution layer."
      ],
      "metadata": {
        "id": "0vjD9mKDYP55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Resize and normalize the images to be suitable for VGG16\n",
        "train_images_resized = tf.image.resize(train_images[4:5], [224, 224])\n",
        "\n",
        "# Normalize the pixel values to [0,1]\n",
        "train_images_resized = train_images_resized / 255.0\n",
        "\n",
        "layer = model.layers[1] # Get the first convolutional layer\n",
        "intermediate_layer_model = tf.keras.models.Model(inputs=model.input, outputs=layer.output)\n",
        "activation = intermediate_layer_model.predict(train_images_resized)\n",
        "\n",
        "# get the feature count from the activations\n",
        "n_features = activation.shape[-1]\n",
        "\n",
        "# Set the figure size\n",
        "plt.figure(figsize=(12, 12))\n",
        "\n",
        "for i in range(n_features):\n",
        "    plt.subplot(8, 8, i+1)  # Assuming 64 features, adjust if necessary\n",
        "    plt.imshow(activation[0, :, :, i], cmap=\"viridis\")\n",
        "    plt.axis('off')"
      ],
      "metadata": {
        "id": "ovrvL1qiVpQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the above code for the forward pass, and the layer indices, plot the activation distributions for the final three dense layers.\n",
        "\n",
        "**Question 5**"
      ],
      "metadata": {
        "id": "IrMUBHLQZXa-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dense layer plot code below"
      ],
      "metadata": {
        "id": "u0DimedIY-JL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What do you notice about the distributions, and how they compare to those of the weight tensors?\n",
        "\n",
        "**Question 6**"
      ],
      "metadata": {
        "id": "SB47GB9BaWzU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NCwIJciVag0r"
      }
    }
  ]
}